[trainer]
n_epochs = 150
log_interval = 20
seed = 0
# Only for tracking environment
source = "Desktop"

[data_loader]
batch_size_train = 128
batch_size_test = 256
# bool
prioritized_sampler = 0
# fit_count
explore_type = fit_count
# pb_error, label_change
exploit_type = label_change
c_constant = 1.0
# ImageNet, Cifar100, Cifar10, TinyImagenet
data_folder_name = Cifar100
num_workers = 4


[augmentation]
# bool
on = 1
probs = 0.9
# bool
crop = 1
crop_probs = 0.8
# bool
horizontal_flip = 1
hf_probs = 0.5
# bool
vertical_flip = 0
vf_probs = 0.5
# bool
color_jitter = 1
jitter_probs = 0.75
# bool
blur = 1
blur_probs = 0.5
# bool
normalize = 0
#bool
cutout = 1
cutout_probs = 0.5
cutout_patch = 3
# bool
adjust_sharpness = 1
sharpness_probs = 0.4

[model]
# resnet50, mobilenet_v3_large, efficientnet_b1, efficientnet_b0
model_type = efficientnet_b1
# bool
pretrained = 0

[callbacks]
# bool
early_stopping_callback = 0
early_stopping_patience = 10
# bool
neptune_logger_callback = 0
neptune_token =
neptune_project =

[agent]
learning_rate = 0.00001
# bool
lr_decay = 1
# cos, on_plateau, lin, exp, warmup_cos, wstep
lr_decay_type = warmup_cos
lr_min = 1e-8
# For wstep
boundaries = 50, 100, 125
values = 0.0018, 0.001, 0.0001, 1e-6
# warmup_epochs for warmup_cos and wstep lr decay
warmup_epochs = 20
warmup_lr_high = 0.003
momentum = 0.9
weight_decay = 0.0002
# cross_entropy, focal_loss
loss = focal_loss
# sgd, adam, rmsprop
optimizer = adam
# Adam parameters
beta1 = 0.9
beta2 = 0.999
amsgrad = 0
# RMSprop parameters
alpha = 0.99
centered = 0
# Adam AND RMSprop parameters
eps = 1e-3